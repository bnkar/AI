import nltk
nltk.download('punkt')
from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
from nltk.tag import pos_tag
nltk.download('averaged_perceptron_tagger')

#Define the text to be analysed
text="This is a sample sentence. It contains multiple words and some of them repeat . We will analyze this text using NLTK"

#Tokenize the text into words
words=word_tokenize(text)
print("tokenized words:")
print(words)

#Convert all words to lowercase
words = [word.lower() for word in words]

#Count the frequency of each word
fdist = FreqDist(words)
print("Word Frequency:")
for word, freq in fdist.items():
    print(f"{word}: {freq}")

#Remove stopwords
stop_words = set(stopwords.words('english'))
filtered_words = [word for word in words if word.casefold() not in stop_words]
print("Filtered Words:")
print(filtered_words)

#Perform POS tagging
pos_tags = pos_tag(words)
print(pos_tags)